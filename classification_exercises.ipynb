{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification Exercises \n",
    "#### Corey Solitaire\n",
    "#### 9/8/2020"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "\n",
    "from math import sqrt\n",
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Acquisition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1 In a jupyter notebook, classification_exercises.ipynb, use a python module (pydata or seaborn datasets) containing datasets as a source from the iris data. Create a pandas dataframe, df_iris, from this data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris = sns.load_dataset('iris')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###   - print the first 3 rows\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(iris.head(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###     - print the number of rows and columns (shape)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(iris.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###    - print the column names\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(iris.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###    - print the data type of each column\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(iris.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#more info is necessary\n",
    "iris.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###     - print the summary statistics for each of the numeric variables. Would you recommend rescaling the data based on these statistics?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(iris.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(iris.sepal_length.var(),\n",
    "iris.sepal_width.var(),\n",
    "iris.petal_length.var(),\n",
    "iris.petal_width.var())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Petal length is much more variable then other measurments, I might reccomend scaling depending on the factors being examined"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Read the Table1_CustDetails table from the Excel_Exercises.xlsx file into a dataframe named df_excel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "customer = pd.read_excel('Spreadsheets_Exercises.xlsx')\n",
    "customer.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###      -assign the first 100 rows to a new dataframe, df_excel_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_excel_sample = customer.head(100)\n",
    "df_excel_sample.info"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###      -print the number of rows of your original dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(customer.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#alternate option\n",
    "customer.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###      -print the first 5 column names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Select First 5 columns:\")\n",
    "print(customer[['customer_id', 'gender', 'is_senior_citizen', 'partner', 'dependents']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# alternate method\n",
    "\n",
    "customer.columns[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###      -print the column names that have a data type of object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filteredColumns = customer.dtypes[customer.dtypes == np.object]\n",
    "listOfColumnNames = list(filteredColumns.index)\n",
    "print(listOfColumnNames)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###     -compute the range for each of the numeric variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Transcribes table\n",
    "stats =customer._get_numeric_data().describe().T\n",
    "stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats['range'] = stats['max'] - stats['min']\n",
    "stats[['mean', '50%', 'std', 'range']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Read the data from this google sheet into a dataframe, df_google"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sheet_url = 'https://docs.google.com/spreadsheets/d/1Uhtml8KY19LILuZsrDtlsHHDC9wuDGUSe8LTEwvdI5g/edit#gid=341089357'    \n",
    "\n",
    "csv_export_url = sheet_url.replace('/edit#gid=', '/export?format=csv&gid=')\n",
    "\n",
    "df_googlesheet = pd.read_csv(csv_export_url)\n",
    "df_googlesheet.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###    -print the first 3 rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_googlesheet.head(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###    -print the number of rows and columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_googlesheet.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###    -print the first five column names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_googlesheet.columns[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# alternate print to list for ease of access\n",
    "df_googlesheet.columns.to_list()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###     -print the data type of each column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_googlesheet.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###     -print the summary statistics for each of the numeric variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_googlesheet._get_numeric_data().describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###   -print the unique values for each of your categorical variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_googlesheet.select_dtypes(object)\n",
    "\n",
    "df_ = df_googlesheet.select_dtypes(exclude=['int', 'float'])\n",
    "for col in df_.columns:\n",
    "    print(df_[col].unique()) # to print categories name only\n",
    "    print(df_[col].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#alternate from faith\n",
    "for col in df_googlesheet:\n",
    "    if df_googlesheet[col].dtypes == 'object':\n",
    "        print(f'{col} has {df_googlesheet[col].nunique()} unique values.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make a new python module, acquire.py to hold the following data aquisition functions:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Make a function named get_titanic_data that returns the titanic data from the codeup data science database as a pandas data frame. Obtain your data from the Codeup Data Science Database. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import env\n",
    "\n",
    "def get_connection(db, user=env.user, host=env.host, password=env.password):\n",
    "    return f'mysql+pymysql://{user}:{password}@{host}/{db}'\n",
    "\n",
    "df = pd.read_sql('SELECT * FROM passengers', get_connection('titanic_db'))\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Make a function named get_iris_data that returns the data from the iris_db on the codeup data science database as a pandas data frame. The returned data frame should include the actual name of the species in addition to the species_ids. Obtain your data from the Codeup Data Science Database. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_iris_data():\n",
    "    return pd.read_sql('SELECT * FROM measurements AS m JOIN species AS s on m.species_id = s.species_id', get_connection('iris_db'))\n",
    "\n",
    "df = get_iris_data()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Once you've got your get_titanic_data and get_iris_data functions written, now it's time to add caching to them. To do this, edit the beginning of the function to check for a local filename like titanic.csv or iris.csv. If they exist, use the .csv file. If the file doesn't exist, then produce the SQL and pandas necessary to create a dataframe, then write the dataframe to a .csv file with the appropriate name. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Titanic Dataset\n",
    "\n",
    "# def get_titanic_data():\n",
    "#     filename = \"titanic.csv\"\n",
    "\n",
    "#     if os.path.isfile(filename):\n",
    "#         return pd.read_csv(filename)\n",
    "#     else:\n",
    "#         # read the SQL query into a dataframe\n",
    "#         df = pd.read_sql('SELECT * FROM passengers', get_connection('titanic_db'))\n",
    "\n",
    "#         # Write that dataframe to disk for later. Called \"caching\" the data for later.\n",
    "#         df.to_csv(filename, index = False)\n",
    "\n",
    "#         # Return the dataframe to the calling code\n",
    "#     return df\n",
    "\n",
    "#import acquire\n",
    "#acquire.get_titanic_data()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Iris Dataset\n",
    "\n",
    "# def get_iris_data():\n",
    "#     filename = \"iris.csv\"\n",
    "\n",
    "#     if os.path.isfile(filename):\n",
    "#        return pd.read_csv(filename)\n",
    "#     else:\n",
    "#         #read the SQL query into a dataframe\n",
    "#         df = pd.read_sql('SELECT * FROM measurements AS m JOIN species AS s on m.species_id = s.species_id', get_connection('iris_db'))\n",
    "\n",
    "#         #Write that dataframe to disk for later. Called \"caching\" the data for later.\n",
    "#         df.to_csv(filename, index = False)\n",
    "\n",
    "#         #Return the dataframe to the calling code\n",
    "#     return df\n",
    "\n",
    "#import acquire\n",
    "#acquire.get_iris_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### - Prepare Enviroment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import acquire\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder, MinMaxScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "- Iris Data\n",
    "\n",
    "    - Use the function defined in acquire.py to load the iris data.\n",
    "    - Drop the species_id and measurement_id columns.\n",
    "    - Rename the species_name column to just species.\n",
    "    - Encode the species name using a sklearn label encoder. Research the inverse_transform method of the label encoder. How might this be useful?\n",
    "    - Create a function named prep_iris that accepts the untransformed iris data, and returns the data with the transformations above applied.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>species_id</th>\n",
       "      <th>species_name</th>\n",
       "      <th>sepal_length</th>\n",
       "      <th>sepal_width</th>\n",
       "      <th>petal_length</th>\n",
       "      <th>petal_width</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>setosa</td>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>setosa</td>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>setosa</td>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>setosa</td>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>setosa</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   species_id species_name  sepal_length  sepal_width  petal_length  \\\n",
       "0           1       setosa           5.1          3.5           1.4   \n",
       "1           1       setosa           4.9          3.0           1.4   \n",
       "2           1       setosa           4.7          3.2           1.3   \n",
       "3           1       setosa           4.6          3.1           1.5   \n",
       "4           1       setosa           5.0          3.6           1.4   \n",
       "\n",
       "   petal_width  \n",
       "0          0.2  \n",
       "1          0.2  \n",
       "2          0.2  \n",
       "3          0.2  \n",
       "4          0.2  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " \n",
    "'''\n",
    "This function reads in iris data from Codeup database if cached == False\n",
    "or if cached == True reads in iris df from a csv file, returns df\n",
    "'''\n",
    "# I ran this code first, to import data and save it as a dataframe\n",
    "#iris = get_iris_data(cached=True)\n",
    "\n",
    "iris = get_iris_data(cached=True)\n",
    "iris.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>species_name</th>\n",
       "      <th>sepal_length</th>\n",
       "      <th>sepal_width</th>\n",
       "      <th>petal_length</th>\n",
       "      <th>petal_width</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>setosa</td>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>setosa</td>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>setosa</td>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>setosa</td>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>setosa</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  species_name  sepal_length  sepal_width  petal_length  petal_width\n",
       "0       setosa           5.1          3.5           1.4          0.2\n",
       "1       setosa           4.9          3.0           1.4          0.2\n",
       "2       setosa           4.7          3.2           1.3          0.2\n",
       "3       setosa           4.6          3.1           1.5          0.2\n",
       "4       setosa           5.0          3.6           1.4          0.2"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Drop the species_id and measurement_id columns.\n",
    "\n",
    "cols_to_drop = ['species_id']\n",
    "iris = iris.drop(columns=cols_to_drop)\n",
    "iris.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>species</th>\n",
       "      <th>sepal_length</th>\n",
       "      <th>sepal_width</th>\n",
       "      <th>petal_length</th>\n",
       "      <th>petal_width</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>setosa</td>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>setosa</td>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>setosa</td>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>setosa</td>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>setosa</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  species  sepal_length  sepal_width  petal_length  petal_width\n",
       "0  setosa           5.1          3.5           1.4          0.2\n",
       "1  setosa           4.9          3.0           1.4          0.2\n",
       "2  setosa           4.7          3.2           1.3          0.2\n",
       "3  setosa           4.6          3.1           1.5          0.2\n",
       "4  setosa           5.0          3.6           1.4          0.2"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Rename the species_name column to just species.\n",
    "\n",
    "iris.rename(columns = {'species_name':'species'}, inplace = True)\n",
    "iris.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((120, 5), (30, 5))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train/Validate/Test Split\n",
    "\n",
    "train_validate, test = train_test_split(iris, test_size=.2, \n",
    "                                        random_state=123, \n",
    "                                        stratify=iris.species)\n",
    "\n",
    "train_validate.shape, test.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((84, 5), (36, 5))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train, validate = train_test_split(train_validate, test_size=.3, \n",
    "                                   random_state=123, \n",
    "                                   stratify=train_validate.species)\n",
    "train.shape, validate.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>species_id</th>\n",
       "      <th>species_name</th>\n",
       "      <th>sepal_length</th>\n",
       "      <th>sepal_width</th>\n",
       "      <th>petal_length</th>\n",
       "      <th>petal_width</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>setosa</td>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>setosa</td>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>setosa</td>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>setosa</td>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>setosa</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   species_id species_name  sepal_length  sepal_width  petal_length  \\\n",
       "0           1       setosa           5.1          3.5           1.4   \n",
       "1           1       setosa           4.9          3.0           1.4   \n",
       "2           1       setosa           4.7          3.2           1.3   \n",
       "3           1       setosa           4.6          3.1           1.5   \n",
       "4           1       setosa           5.0          3.6           1.4   \n",
       "\n",
       "   petal_width  \n",
       "0          0.2  \n",
       "1          0.2  \n",
       "2          0.2  \n",
       "3          0.2  \n",
       "4          0.2  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris = get_iris_data(cached=True)\n",
    "iris.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method NDFrame.head of      species_id species_name  sepal_length  sepal_width  petal_length  \\\n",
       "0             1       setosa           5.1          3.5           1.4   \n",
       "1             1       setosa           4.9          3.0           1.4   \n",
       "2             1       setosa           4.7          3.2           1.3   \n",
       "3             1       setosa           4.6          3.1           1.5   \n",
       "4             1       setosa           5.0          3.6           1.4   \n",
       "..          ...          ...           ...          ...           ...   \n",
       "145           3    virginica           6.7          3.0           5.2   \n",
       "146           3    virginica           6.3          2.5           5.0   \n",
       "147           3    virginica           6.5          3.0           5.2   \n",
       "148           3    virginica           6.2          3.4           5.4   \n",
       "149           3    virginica           5.9          3.0           5.1   \n",
       "\n",
       "     petal_width  species_name_versicolor  species_name_virginica  \n",
       "0            0.2                        0                       0  \n",
       "1            0.2                        0                       0  \n",
       "2            0.2                        0                       0  \n",
       "3            0.2                        0                       0  \n",
       "4            0.2                        0                       0  \n",
       "..           ...                      ...                     ...  \n",
       "145          2.3                        0                       1  \n",
       "146          1.9                        0                       1  \n",
       "147          2.0                        0                       1  \n",
       "148          2.3                        0                       1  \n",
       "149          1.8                        0                       1  \n",
       "\n",
       "[150 rows x 8 columns]>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We do not need to use sklearn, we can just make dummy variables\n",
    "\n",
    "df_dummies = pd.get_dummies(iris[['species_name']], drop_first=[True, True])\n",
    "iris = pd.concat([iris, df_dummies], axis=1)\n",
    "iris.head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode the species name using a sklearn label encoder. \n",
    "# Research the inverse_transform method of the label encoder. How might this be useful?\n",
    "\n",
    "def label_encode(train, test):\n",
    "    le = LabelEncoder()\n",
    "    train['species'] = le.fit_transform(train.species)\n",
    "    test['species'] = le.transform(test.species)\n",
    "    return le, train, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(LabelEncoder(),\n",
       "      species  sepal_length  sepal_width  petal_length  petal_width\n",
       " 79         1           5.7          2.6           3.5          1.0\n",
       " 36         0           5.5          3.5           1.3          0.2\n",
       " 133        2           6.3          2.8           5.1          1.5\n",
       " 95         1           5.7          3.0           4.2          1.2\n",
       " 18         0           5.7          3.8           1.7          0.3\n",
       " ..       ...           ...          ...           ...          ...\n",
       " 11         0           4.8          3.4           1.6          0.2\n",
       " 85         1           6.0          3.4           4.5          1.6\n",
       " 55         1           5.7          2.8           4.5          1.3\n",
       " 44         0           5.1          3.8           1.9          0.4\n",
       " 73         1           6.1          2.8           4.7          1.2\n",
       " \n",
       " [84 rows x 5 columns],\n",
       "      species  sepal_length  sepal_width  petal_length  petal_width\n",
       " 80         1           5.5          2.4           3.8          1.1\n",
       " 45         0           4.8          3.0           1.4          0.3\n",
       " 144        2           6.7          3.3           5.7          2.5\n",
       " 110        2           6.5          3.2           5.1          2.0\n",
       " 38         0           4.4          3.0           1.3          0.2\n",
       " 2          0           4.7          3.2           1.3          0.2\n",
       " 135        2           7.7          3.0           6.1          2.3\n",
       " 72         1           6.3          2.5           4.9          1.5\n",
       " 138        2           6.0          3.0           4.8          1.8\n",
       " 34         0           4.9          3.1           1.5          0.2\n",
       " 19         0           5.1          3.8           1.5          0.3\n",
       " 77         1           6.7          3.0           5.0          1.7\n",
       " 101        2           5.8          2.7           5.1          1.9\n",
       " 63         1           6.1          2.9           4.7          1.4\n",
       " 117        2           7.7          3.8           6.7          2.2\n",
       " 76         1           6.8          2.8           4.8          1.4\n",
       " 42         0           4.4          3.2           1.3          0.2\n",
       " 22         0           4.6          3.6           1.0          0.2\n",
       " 28         0           5.2          3.4           1.4          0.2\n",
       " 33         0           5.5          4.2           1.4          0.2\n",
       " 17         0           5.1          3.5           1.4          0.3\n",
       " 116        2           6.5          3.0           5.5          1.8\n",
       " 127        2           6.1          3.0           4.9          1.8\n",
       " 56         1           6.3          3.3           4.7          1.6\n",
       " 105        2           7.6          3.0           6.6          2.1\n",
       " 146        2           6.3          2.5           5.0          1.9\n",
       " 93         1           5.0          2.3           3.3          1.0\n",
       " 86         1           6.7          3.1           4.7          1.5\n",
       " 68         1           6.2          2.2           4.5          1.5\n",
       " 65         1           6.7          3.1           4.4          1.4)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_encode(train, test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Research the inverse_transform method of the label encoder. How might this be useful?\n",
    "\n",
    "'''\n",
    "Used to transform the data back in to categories after modeling for analysis\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a function named prep_iris that accepts the untransformed iris data, and returns the data with the transformations above applied.\n",
    "\n",
    "def prep_iris(df):\n",
    "    le = LabelEncoder()\n",
    "    df = df.drop(columns='species_id')\n",
    "    df = df.rename(columns={'species_name': 'species'})\n",
    "    train, test = train_test_split(df, train_size=.75, stratify=df.species, random_state=123)\n",
    "    train, test, le = label_encode(train, test)\n",
    "    return le, train, test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"['species_id'] not found in axis\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-905504f71ff5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprep_iris\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miris\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-16-0b00619edc21>\u001b[0m in \u001b[0;36mprep_iris\u001b[0;34m(df)\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mprep_iris\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLabelEncoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'species_id'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrename\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'species_name'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'species'\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m.75\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstratify\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mspecies\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m123\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36mdrop\u001b[0;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[1;32m   3988\u001b[0m                 \u001b[0mweight\u001b[0m  \u001b[0;36m1.0\u001b[0m     \u001b[0;36m0.8\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3989\u001b[0m         \"\"\"\n\u001b[0;32m-> 3990\u001b[0;31m         return super().drop(\n\u001b[0m\u001b[1;32m   3991\u001b[0m             \u001b[0mlabels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3992\u001b[0m             \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36mdrop\u001b[0;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[1;32m   3934\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;32min\u001b[0m \u001b[0maxes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3935\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3936\u001b[0;31m                 \u001b[0mobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_drop_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3937\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3938\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m_drop_axis\u001b[0;34m(self, labels, axis, level, errors)\u001b[0m\n\u001b[1;32m   3968\u001b[0m                 \u001b[0mnew_axis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3969\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3970\u001b[0;31m                 \u001b[0mnew_axis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3971\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreindex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0maxis_name\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mnew_axis\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3972\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mdrop\u001b[0;34m(self, labels, errors)\u001b[0m\n\u001b[1;32m   5016\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0many\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5017\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0merrors\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m\"ignore\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5018\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"{labels[mask]} not found in axis\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5019\u001b[0m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m~\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5020\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdelete\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: \"['species_id'] not found in axis\""
     ]
    }
   ],
   "source": [
    "prep_iris(iris)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Titanic Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####     Use the function you defined in acquire.py to load the titanic data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "This function reads in titanic data from Codeup database if cached == False\n",
    "or if cached == True reads in iris df from a csv file, returns df\n",
    "'''\n",
    "# I ran this code first, to import data and save it as a dataframe\n",
    "#iris = get_iris_data(cached=True)\n",
    "\n",
    "titanic = get_titanic_data(cached=True)\n",
    "titanic.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####     Handle the missing values in the embark_town and embarked columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropped these colums because they are repeats, or do not provide extra insight in to who survived\n",
    "cols_to_drop = ['embarked', 'class', 'passenger_id']\n",
    "titanic = titanic.drop(columns=cols_to_drop)\n",
    "titanic.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop missing observations of embark town\n",
    "titanic = titanic[~titanic.embark_town.isnull()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####     Remove the deck column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_to_drop = ['deck']\n",
    "titanic = titanic.drop(columns=cols_to_drop)\n",
    "titanic.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####    Use a label encoder to transform the embarked column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#first we have to train/validate/test split data\n",
    "\n",
    "train_validate, test = train_test_split(titanic, test_size=.2, \n",
    "                                        random_state=123, \n",
    "                                        stratify=titanic.survived)\n",
    "\n",
    "train, validate = train_test_split(train_validate, test_size=.3, \n",
    "                                   random_state=123, \n",
    "                                   stratify=train_validate.survived)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def label_encode(train, test):\n",
    "    le = LabelEncoder()\n",
    "    train['embark_town'] = le.fit_transform(train.embark_town)\n",
    "    test['embark_town'] = le.transform(test.embark_town)\n",
    "    return le, train, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_encode(train, test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####     Scale the age and fare columns using a min max scaler. Why might this be beneficial? When might you not want to do this?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scale_columns(train, test):\n",
    "    scaler = MinMaxScaler()\n",
    "    train[['age','fare']] = scaler.fit_transform(train[['age','fare']])\n",
    "    test[['age','fare']] = scaler.transform(test[['age','fare']])\n",
    "    return scaler, train, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scale_columns(train, test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####     Fill the missing values in age. The way you fill these values is up to you. Consider the tradeoffs of different methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def impute_age(train, test):\n",
    "    avg_age = train.age.mean()\n",
    "    train.age = train.age.fillna(avg_age)\n",
    "    test.age = test.age.fillna(avg_age)\n",
    "    return train, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "impute_age(train, test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####     Create a function named prep_titanic that accepts the untransformed titanic data, and returns the data with the   transformations above applied."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic = get_titanic_data(cached=True)\n",
    "titanic.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#prep_titanic_2\n",
    "\n",
    "def drop_edit_columns(df):\n",
    "    titanic = titanic[~titanic.embark_town.isnull()]\n",
    "    cols_to_drop = ['embarked', 'class', 'deck', 'passenger_id']\n",
    "    titanic = titanic.drop(columns=cols_to_drop)\n",
    "    titanic.head()\n",
    "    return df\n",
    "\n",
    "def test_split(df):\n",
    "    train_validate, test = train_test_split(titanic, test_size=.2, \n",
    "                                        random_state=123, \n",
    "                                        stratify=titanic.survived)\n",
    "    train, validate = train_test_split(train_validate, test_size=.3, \n",
    "                                   random_state=123, \n",
    "                                   stratify=train_validate.survived)\n",
    "    return df\n",
    "\n",
    "def label_encode(train, test):\n",
    "    le = LabelEncoder()\n",
    "    train['embark_town'] = le.fit_transform(train.embark_town)\n",
    "    test['embark_town'] = le.transform(test.embark_town)\n",
    "    return le, train, test\n",
    "\n",
    "def scale_columns(train, test):\n",
    "    scaler = MinMaxScaler()\n",
    "    train[['age','fare']] = scaler.fit_transform(train[['age','fare']])\n",
    "    test[['age','fare']] = scaler.transform(test[['age','fare']])\n",
    "    return scaler, train, test\n",
    "\n",
    "def impute_age(train, test):\n",
    "    avg_age = train.age.mean()\n",
    "    train.age = train.age.fillna(avg_age)\n",
    "    test.age = test.age.fillna(avg_age)\n",
    "    return train, test\n",
    "\n",
    "def prep_titanic_2(df):\n",
    "\n",
    "    # drop the deck column bc most values Null\n",
    "    drop_edit_columns\n",
    "    \n",
    "    train, test = train_test_split(df, train_size=.75, stratify=df.survived, random_state=123)\n",
    "    \n",
    "    # impute embarked town to 0,1,2\n",
    "    train, test = label_encode_town(train, test)\n",
    "    \n",
    "    # scale age and fare columns\n",
    "    train, test = scale_columns(train, test)\n",
    "    \n",
    "    # impute NaNs in age in train and test with the mean age in train\n",
    "    train, test = impute_age(train, test)\n",
    "    \n",
    "    return scaler, train, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop_columns(df):\n",
    "    df.drop(columns=['deck'], inplace=True)\n",
    "    return df\n",
    "\n",
    "def impute_embark_town(train, test):\n",
    "    train['embark_town'] = train['embark_town'].fillna('Southampton')\n",
    "    test['embark_town'] = test['embark_town'].fillna('Southampton')\n",
    "    return train, test\n",
    "\n",
    "def impute_embarked(train, test):\n",
    "    train['embarked'] = train['embarked'].fillna('S')\n",
    "    test['embarked'] = test['embarked'].fillna('S')\n",
    "    return train, test\n",
    "\n",
    "def impute_age(train, test):\n",
    "    avg_age = train.age.mean()\n",
    "    train.age = train.age.fillna(avg_age)\n",
    "    test.age = test.age.fillna(avg_age)\n",
    "    return train, test\n",
    "\n",
    "def scale_columns(train, test):\n",
    "    scaler = MinMaxScaler()\n",
    "    train[['age','fare']] = scaler.fit_transform(train[['age','fare']])\n",
    "    test[['age','fare']] = scaler.transform(test[['age','fare']])\n",
    "    return scaler, train, test\n",
    "\n",
    "def ohe_columns(train, test):\n",
    "    # create encoder\n",
    "    ohe = OneHotEncoder(sparse=False, categories='auto')\n",
    "    \n",
    "    # fit scaler on train and transform train and test to dense matrices\n",
    "    train_matrix = ohe.fit_transform(train[['embarked']])\n",
    "    test_matrix = ohe.transform(test[['embarked']])\n",
    "    \n",
    "    # transform matrices to DataFrames\n",
    "    train_ohe = pd.DataFrame(train_matrix, columns=ohe.categories_[0], index=train.index)\n",
    "    test_ohe = pd.DataFrame(test_matrix, columns=ohe.categories_[0], index=test.index)\n",
    "    \n",
    "    # join encoded matrix with original train or test matrices\n",
    "    train = train.join(train_ohe)\n",
    "    test = test.join(test_ohe)\n",
    "    \n",
    "    return ohe, train, test\n",
    "\n",
    "def prep_titanic(df):\n",
    "\n",
    "    # drop the deck column bc most values Null\n",
    "    drop_columns(df)\n",
    "    \n",
    "    train, test = train_test_split(df, train_size=.75, stratify=df.survived, random_state=123)\n",
    "    \n",
    "    # impute 2 NaNs in embark_town with most frequent value\n",
    "    train, test = impute_embark_town(train, test)\n",
    "    \n",
    "    # impute 2 NaNs in embarked with most frequent value\n",
    "    train, test = impute_embarked(train, test)\n",
    "    \n",
    "    # impute NaNs in age in train and test with the mean age in train\n",
    "    train, test = impute_age(train, test)\n",
    "    \n",
    "    # use a minmax scaler on age and fare bc of differing measurement units\n",
    "    scaler, train, test = scale_columns(train, test)\n",
    "    \n",
    "    # ohe embarked creating three new columns for C, Q, S representing embark towns\n",
    "    ohe, train, test = ohe_columns(train, test)\n",
    "    \n",
    "    return scaler, ohe, train, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
